{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Remarques\n",
        "\n",
        "J'ai changé mon backend pour PyTorch car PyTorch dispose de plus de fonctions pré-implémentées qui s'occuppent du calcul de gradient dans la backpropagation que Paddle et parce qu'on a utilisé PyTorch dans le cours de Deep Learning.\n",
        "\n",
        "Avec les modifications faites, changer l'emplacement de la source à un impact sur le résultat lorsque le terme de source est différent de $0$. Cependant il y a toujours ce problème de valeurs bizarres en $(x,y) = (0, 0)$\n",
        "\n",
        "J'ai rempacé le Dirac par une gaussienne pour représenter la source car GPT m'a expliqué qu'utiliser des fonctions non régulières peut poser des problèmes numériques pour l'entraînement.\n",
        "\n",
        "Il y a peut etre trop peut de points d'entrainement: si on voulait qu'il y ait un point d'entrainement tous les 1 m et toutes les 0.1 s il faudrait\n",
        "500 * 500 * 100 = 25 000 000 points d'entrainement ! Je pense que le problème majeur est que le modèle n'arrive pas à apprendre la condition initiale, ce qui cause les problèmes au point $(0, 0)$ et ces problèmes se propagent ensuite lorsque $t$ augmente.\n",
        "J'ai rajouté des points autours de $(x,y)=(0,0)$ et j'ai augmenté le nombre de couches dans le réseau de neurones et ça semble atténuer ce problème: maintenant il à l'air de comprendre la condition initiale. Le problème à l'air d'être la diffusion maintenant.\n",
        "\n",
        "Est-ce que le probleme est bien posé ? Est-ce qu'une condition initiale suffit ?\n",
        "Modif: En fait ChatGPT m'a dit que pour des equations d'advection diffusion il faut quand meme imposer des conditions aux limites afin d'avoir une unique solution meme si le bord du domaine ne correspond a rien en particulier. J'ai donc rajouté une condition aux limite de Dirichlet qui fait en sorte que C vaille 0 au bord. Cela pourrait bien representer le phenomene physique etudie si on choisit $D$ et $u$ assez faibles pour que sur la periode de temps etudiée le polluant n'ait pas le temps de sortir du domaine etudié."
      ],
      "metadata": {
        "id": "vfEtg6mdomkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepxde"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC4OCz5zrHHf",
        "outputId": "9751b95d-48db-4ded-93e8-69932a1cde20"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepxde\n",
            "  Downloading DeepXDE-1.11.0-py3-none-any.whl (179 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.8/179.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from deepxde) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepxde) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepxde) (1.2.2)\n",
            "Collecting scikit-optimize>=0.9.0 (from deepxde)\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from deepxde) (1.11.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize>=0.9.0->deepxde) (1.3.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize>=0.9.0->deepxde)\n",
            "  Downloading pyaml-23.12.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepxde) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde) (2.8.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize>=0.9.0->deepxde) (6.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->deepxde) (1.16.0)\n",
            "Installing collected packages: pyaml, scikit-optimize, deepxde\n",
            "Successfully installed deepxde-1.11.0 pyaml-23.12.0 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On choisit le backend souahite\n",
        "import os\n",
        "\n",
        "os.environ['DDE_BACKEND'] = 'pytorch'\n",
        "\n",
        "import deepxde as dde"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzn05r3owGk9",
        "outputId": "77abf46d-a2ad-4826-da91-920e2cbd9c1f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using backend: pytorch\n",
            "Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.\n",
            "paddle supports more examples now and is recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import griddata\n",
        "import matplotlib.colors"
      ],
      "metadata": {
        "id": "GFgTsoXRpZLx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fait en sorte que tous les tenseurs soient crees sur le GPU (s'il est accessible)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.set_device(0)"
      ],
      "metadata": {
        "id": "6sNIw2epySAP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition des parametres\n",
        "Lx = 500 # largeur du domaine\n",
        "Ly = 500 # longueur du domaine\n",
        "u = np.array([0, 0])  # (ux, uy)\n",
        "D = 75**2 / 10  # coeff de diffusion\n",
        "T = 10  # temps final\n",
        "coords_S = torch.tensor([Lx/4, Lx/4])  # coordonnees de la source\n",
        "S = 1000  # valeur de la source\n",
        "spatial_res = 50 # resolution spatiale pour l'espacement des point d'entrainement\n",
        "time_res = 20 # resolution temporelle"
      ],
      "metadata": {
        "id": "3p6kvLDNo9cZ"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "Adn3zLIAoe_j"
      },
      "outputs": [],
      "source": [
        "# Definition des domaines de temps et d'espace\n",
        "geom = dde.geometry.geometry_2d.Rectangle([-Lx / 2, -Ly / 2], [Lx / 2, Ly / 2])\n",
        "timedomain = dde.geometry.TimeDomain(0, T)\n",
        "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
        "\n",
        "\n",
        "def normal_pdf(z, mu):\n",
        "    \"\"\"densite d'une gaussienne non normalisee ou Cov = 5Id\n",
        "    z est un array 2d ou chaque ligne correspond a une position spatiale (x,y)\"\"\"\n",
        "    res = torch.sum(torch.square(z - mu), dim=-1) # norme 2 au carre des lignes\n",
        "    res = torch.exp(- res / 2)\n",
        "    return res.view((-1, 1))\n",
        "\n",
        "\n",
        "def pde(p, C):\n",
        "    \"\"\"residu de l'equadif\n",
        "    p contient les coordonnes spatiales x, y et le temps t\n",
        "    ainsi si on s'interesse au point i de coordonnees (xi, yi, ti)\n",
        "    il est stocke dans p a la ieme ligne et on a donc\n",
        "    p[i, 0] = xi; p[i, 1] = yi; p[i, 2] = ti\n",
        "    C correspond a C(p) la concentration en p\"\"\"\n",
        "\n",
        "    dC_x = dde.grad.jacobian(C, p, j=0)\n",
        "    dC_y = dde.grad.jacobian(C, p, j=1)\n",
        "    dC_t = dde.grad.jacobian(C, p, j=2)\n",
        "\n",
        "    dC_xx = dde.grad.hessian(C, p, i=0, j=0)\n",
        "    dC_yy = dde.grad.hessian(C, p, i=1, j=1)\n",
        "\n",
        "    return (\n",
        "        - dC_t\n",
        "        - u[0] * dC_x\n",
        "        - u[1] * dC_y\n",
        "        + D * (dC_xx + dC_yy)\n",
        "        + normal_pdf(p[:, 0:2], coords_S) * S\n",
        "    )\n",
        "\n",
        "\n",
        "# Definition des conditions aux limites\n",
        "coords_S_np = coords_S.cpu().numpy()\n",
        "nb_source_points = time_res\n",
        "times = np.linspace(0, T, nb_source_points)\n",
        "source_points = np.tile(coords_S_np, (nb_source_points, 1))\n",
        "source_points_time = np.c_[ source_points, times]\n",
        "\n",
        "# Plus de points autours de (0,0) pour combattre un bug\n",
        "#points_around_zero = []\n",
        "#for x in np.linspace(-Lx/20, Lx/20, 2):\n",
        "#  for y in np.linspace(-Ly/10, Ly/10, 2):\n",
        "#    for t in np.linspace(0, T, 2):\n",
        "#      points_around_zero.append([x, y, t])\n",
        "#points_around_zero = np.array(points_around_zero)\n",
        "\n",
        "#anchor_points = np.concatenate([source_points_time, points_around_zero], axis=0)\n",
        "anchor_points = source_points_time\n",
        "\n",
        "def initial_condition(p):\n",
        "    p_tensor = torch.tensor(p)\n",
        "    return normal_pdf(p_tensor[:, 0:2], coords_S) * S\n",
        "\n",
        "\n",
        "ic = dde.icbc.IC(geomtime, initial_condition, lambda _, on_initial: on_initial)\n",
        "\n",
        "bc = dde.icbc.DirichletBC(geomtime, lambda x: 0, lambda _, on_boundary: on_boundary)\n",
        "\n",
        "\n",
        "# On concatene tout dans data\n",
        "data = dde.data.TimePDE(\n",
        "    geomtime,\n",
        "    pde,\n",
        "    [ic, bc],\n",
        "    num_domain = spatial_res**2 * time_res,\n",
        "    num_boundary = 2 * spatial_res,\n",
        "    num_initial = spatial_res**2,\n",
        "    anchors=anchor_points,\n",
        ")\n",
        "\n",
        "\n",
        "# Definition de l'architecture du reseau de neurones\n",
        "net = dde.nn.FNN([3] + [20] * 8 + [1], \"tanh\", \"Glorot normal\")\n",
        "model = dde.Model(data, net)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrainement de reseau de neurones\n",
        "model.compile(\"adam\", lr=1e-2)\n",
        "losshistory, train_state = model.train(iterations=5000)\n",
        "#model.compile(\"L-BFGS\")\n",
        "#losshistory, train_state = model.train()\n",
        "# dde.saveplot(losshistory, train_state, issave=True, isplot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZB-YjJ3pF-7",
        "outputId": "1f8f629b-5f54-447f-9184-a7e049a8a84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiling model...\n",
            "'compile' took 0.001495 s\n",
            "\n",
            "Training model...\n",
            "\n",
            "Step      Train loss                        Test loss                         Test metric\n",
            "0         [4.00e+02, 4.00e+02, 5.55e-02]    [4.00e+02, 4.00e+02, 5.55e-02]    []  \n",
            "1000      [3.96e+02, 3.99e+02, 1.07e-01]    [3.96e+02, 3.99e+02, 1.07e-01]    []  \n",
            "2000      [3.96e+02, 3.99e+02, 8.30e-02]    [3.96e+02, 3.99e+02, 8.30e-02]    []  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test: on affiche le resultat au temps t\n",
        "t = 10\n",
        "x = geom.uniform_points(250 * 250, True)\n",
        "p = np.c_[x, np.array([t] * x.shape[0])]\n",
        "y = model.predict(p, operator=pde)\n",
        "\n",
        "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
        "    \"\", [\"blue\", \"violet\", \"red\"]\n",
        ")\n",
        "\n",
        "resolution_mesh = 250\n",
        "xi = np.linspace(-Lx / 2, Lx / 2, resolution_mesh)\n",
        "yi = np.linspace(-Ly / 2, Ly / 2, resolution_mesh)\n",
        "xi, yi = np.meshgrid(xi, yi)\n",
        "\n",
        "zi = griddata((x[:, 0], x[:, 1]), y[:, 0], (xi, yi), method=\"linear\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.pcolormesh(xi, yi, zi, cmap=cmap, shading=\"auto\")\n",
        "plt.colorbar(label=\"Prédiction\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.title(\"Distribution des prédictions à t={}\".format(t))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GO4mS3rVpH51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WTbnetIR8Ld3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}